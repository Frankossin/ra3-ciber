{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb/cKnntyVtZbJ1nJ8sqIu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frankossin/ra3-ciber/blob/main/Atividade_Avaliativa_RA3_1_sem%C3%A1foros_2023_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atividade Prática Avaliativa Em Grupo - RA3-1\n",
        "Para realizar esta atividade e conseguir os pontos equivalentes na média da RA-3 você deve fazer uma cópia deste notebook, manter inalterado este enunciado, incluir o nome de todos os componentes do grupo e, finalmente resolver o exercício a seguir em uma célula de código: \n",
        "\n",
        "Seu objetivo é escrever um programa Python que recupere o texto de cinco páginas diferentes da Wikipedia. Cada página deve ser recuperada por uma thread diferente.\n",
        "\n",
        "O programa deve cumprir os seguintes requisitos:\n",
        "\n",
        "1. Use a biblioteca requests para realizar requisições HTTP GET para as páginas da Wikipedia.\n",
        "2. Use a biblioteca BeautifulSoup para extrair o texto das páginas da web.\n",
        "3. Crie uma thread para cada página da Wikipedia que você está acessando.\n",
        "4. Cada thread deve escrever o texto extraído no mesmo arquivo de texto compartilhado.\n",
        "5. Garanta que não ocorram condições de corrida ao escrever no arquivo de texto compartilhado.\n",
        "6. O thread que gravou cada texto no arquivo deve ser identificado no próprio texto gravado e em uma impressão no terminal que permita acompanhar o processo de gravação. \n",
        "\n",
        "Lembre-se não podem haver condições de corrida. Use semáforos. "
      ],
      "metadata": {
        "id": "cWEbfRvkFQ3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxYC16MAFMOR",
        "outputId": "df8b4bd0-a501-42d7-e716-c53518fb26dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread Thread2 gravou texto no arquivo.\n",
            "Thread Thread4 gravou texto no arquivo.\n",
            "Thread Thread1 gravou texto no arquivo.\n",
            "Thread Thread5 gravou texto no arquivo.\n",
            "Thread Thread3 gravou texto no arquivo.\n"
          ]
        }
      ],
      "source": [
        "#Franklin Jeronimo Belasque Bauch Vieira, Caike Augusto, Vinicius Zaia, Eduardo de Abreu\n",
        "#Por favor abra no colab e teste o codigo la, pois esta e a unica forma do arquivo ser criado para voce poder visualiza-lo.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import threading\n",
        "\n",
        "\n",
        "urls = [\"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n",
        "        \"https://en.wikipedia.org/wiki/Data_science\",\n",
        "        \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
        "        \"https://en.wikipedia.org/wiki/Machine_learning\",\n",
        "        \"https://en.wikipedia.org/wiki/Deep_learning\"]\n",
        "\n",
        "semaphore = threading.Semaphore()\n",
        "\n",
        "def get_wiki_page(url):\n",
        "    \n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "\n",
        "    semaphore.acquire()\n",
        "    try:\n",
        "        with open(\"output.txt\", \"a\") as f:\n",
        "            f.write(f\"Thread {threading.current_thread().name}:\\n\")\n",
        "            f.write(text + \"\\n\")\n",
        "\n",
        "        print(f\"Thread {threading.current_thread().name} gravou texto no arquivo.\")\n",
        "    finally:\n",
        "        semaphore.release()\n",
        "\n",
        "# Cria uma thread para cada página da wikipedia\n",
        "threads = []\n",
        "for i, url in enumerate(urls):\n",
        "    thread = threading.Thread(target=get_wiki_page, args=(url,), name=f\"Thread{i+1}\")\n",
        "    thread.start()\n",
        "    threads.append(thread)\n",
        "\n",
        "# Aguarda todas as threads terminarem\n",
        "for thread in threads:\n",
        "    thread.join()"
      ]
    }
  ]
}